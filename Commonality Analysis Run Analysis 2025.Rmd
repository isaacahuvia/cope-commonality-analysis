---
title: "Commonality Analysis Code_2"
author: "Laura Jans and Arielle Smith"
date: "2025-08-07"
output: html_document
---

```{r versions documentation}
#R version 4.4.0 (2024-04-24)
#tidyverse version 2.0.0
#yhat version 2.0-4
#boot version 1.3-3.0
#car version 3.0-5
#lmtest version 0.9-4.0
#olsrr version 0.6.0
```


# Loading Cleaned Data

```{r setup, echo=TRUE, message=FALSE, warning=FALSE}

#Load required packages

if(!require(tidyverse)){install.packages('tidyverse')}
library(tidyverse)

if(!require(yhat)){install.packages('yhat')}
library(yhat)

if(!require(boot)){install.packages('boot')}
library(boot)

if(!require(car)){install.packages('car')}
library(car)

if(!require(lmtest)){install.packages('lmtest')}
library(lmtest)

if(!require(olsrr)){install.packages('olsrr')}
library(olsrr)

#Read in data from data cleaning and pre-processing code (to avoid re-running data prep every time)

cope_ca_data_imputed <- read.csv("cope_ca_data_imputed.csv")
cope_ca_data_nonimputed <- read.csv("cope_ca_data_nonimputed.csv")

set.seed(6804275)
```


# Creating Difference Scores

## Dependent Variable
```{r}
#Creating difference scores for depression (pre-SSI to 3M) in both the imputed and non-imputed datasets
cope_ca_data_imputed <- cope_ca_data_imputed %>% 
  mutate(difference_score_cdi = f1_cdi_sum - b_cdi_sum)
cope_ca_data_nonimputed <- cope_ca_data_nonimputed %>% 
  mutate(difference_score_cdi = f1_cdi_sum - b_cdi_sum)
```

## Independent Variables

```{r}
#Creating difference scores for hopelessness (pre-SSI to post-SSI) in both the imputed and non-imputed datasets 
cope_ca_data_imputed <- cope_ca_data_imputed %>% 
  mutate(difference_score_bhs = pi_bhs_mean - b_bhs_mean)
cope_ca_data_nonimputed <- cope_ca_data_nonimputed %>% 
  mutate(difference_score_bhs = pi_bhs_mean - b_bhs_mean)

#Creating difference scores for agency (pre-SSI to post-SSI) in both the imputed and non-imputed datasets 
cope_ca_data_imputed <- cope_ca_data_imputed %>% 
  mutate(difference_score_shs = pi_shs_mean - b_shs_mean)
cope_ca_data_nonimputed <- cope_ca_data_nonimputed %>% 
  mutate(difference_score_shs = pi_shs_mean - b_shs_mean)
```


# Running Regressions (Imputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# Subset data based on condition

cope_ca_data_imputed_PP <- subset(cope_ca_data_imputed, condition == 1)
cope_ca_data_imputed_ABC <- subset(cope_ca_data_imputed, condition == 2)

# Run main regressions

# Project Personality, Imputed

cdi_PP_imputed <- lm(difference_score_cdi ~ difference_score_bhs + difference_score_shs + pi_pfs_mean, data = cope_ca_data_imputed_PP)
summary(cdi_PP_imputed)

# ABC Project, Imputed

cdi_ABC_imputed <- lm(difference_score_cdi ~ difference_score_bhs + difference_score_shs + pi_pfs_mean, data = cope_ca_data_imputed_ABC)
summary(cdi_ABC_imputed)
```
Note: We decided to use mean for the PFS instead of component scores.


# Commonality Analysis (Imputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# First, let's look at the r^2 for each model

summary(cdi_PP_imputed)$r.squared
summary(cdi_ABC_imputed)$r.squared

# Decompose r^2 # Let's just try this once for the model predicting follow-up depression symptoms for Project Personality 

regOut_cdi_PP <- calc.yhat(cdi_PP_imputed)
#regOut_cdi_PP$APSRelatedMetrics

# Bootstrap 1000 times to get CIs

boot.regOut_cdi_PP <-boot(cope_ca_data_imputed_PP, boot.yhat, 1000, lmOut = cdi_PP_imputed, regrout0 = regOut_cdi_PP)
boot.regOut_cdi_PP_result <- booteval.yhat(regOut_cdi_PP, boot.regOut_cdi_PP, bty="perc")
print(boot.regOut_cdi_PP_result$combCIaps)
print(boot.regOut_cdi_PP_result$combCIpm["b"])
print(boot.regOut_cdi_PP_result$combCIapsDiff)

# Now, need to get total effects for each IV individually

# Hopelessness 

# Define function to get R^2 
rsq <- function(cope_ca_data_imputed_PP, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ difference_score_bhs, # Whatever the regression formula is 
    data = cope_ca_data_imputed_PP[bootstrap_rows,] # This changes the rows of the dataset to whatever the rows are for that specific bootstrap iteration 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
# Point estimate 
rsq(cope_ca_data_imputed_PP, 1:nrow(cope_ca_data_imputed_PP)) 
# Bootstrap results 
bootstrapped_results <- boot(data = cope_ca_data_imputed_PP, statistic = rsq, R = 1000) 
# CI for R^2 
boot.ci(bootstrapped_results, type = "perc") 

# Agency 

rsq <- function(cope_ca_data_imputed_PP, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ difference_score_shs,
    data = cope_ca_data_imputed_PP[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_imputed_PP, 1:nrow(cope_ca_data_imputed_PP)) 
bootstrapped_results <- boot(data = cope_ca_data_imputed_PP, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 

# Acceptability

rsq <- function(cope_ca_data_imputed_PP, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ pi_pfs_mean,
    data = cope_ca_data_imputed_PP[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_imputed_PP, 1:nrow(cope_ca_data_imputed_PP)) 
bootstrapped_results <- boot(data = cope_ca_data_imputed_PP, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 

# Project ABC, Depression

regOut_cdi_ABC <- calc.yhat(cdi_ABC_imputed)
#regOut_dep_ABC$APSRelatedMetrics

boot.regOut_cdi_ABC <- boot(cope_ca_data_imputed_ABC, boot.yhat, 1000, lmOut = cdi_ABC_imputed, regrout0 = regOut_cdi_ABC)
boot.regOut_cdi_ABC_result <- booteval.yhat(regOut_cdi_ABC, boot.regOut_cdi_ABC, bty = "perc")
print(boot.regOut_cdi_ABC_result$combCIaps)
print(boot.regOut_cdi_ABC_result$combCIpm["b"])
print(boot.regOut_cdi_ABC_result$combCIapsDiff)

# Hopelessness

rsq <- function(cope_ca_data_imputed_ABC, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ difference_score_bhs,
    data = cope_ca_data_imputed_ABC[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_imputed_ABC, 1:nrow(cope_ca_data_imputed_ABC)) 
bootstrapped_results <- boot(data = cope_ca_data_imputed_ABC, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 

# Agency 

rsq <- function(cope_ca_data_imputed_ABC, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ difference_score_shs,
    data = cope_ca_data_imputed_ABC[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_imputed_ABC, 1:nrow(cope_ca_data_imputed_ABC)) 
bootstrapped_results <- boot(data = cope_ca_data_imputed_ABC, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 

# Acceptability

rsq <- function(cope_ca_data_imputed_ABC, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ pi_pfs_mean,
    data = cope_ca_data_imputed_ABC[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_imputed_ABC, 1:nrow(cope_ca_data_imputed_ABC)) 
bootstrapped_results <- boot(data = cope_ca_data_imputed_ABC, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 
```


# Regression assumptions (Imputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# Multicollinearity
sqrt(vif(cdi_PP_imputed)) # should be less than 2
sqrt(vif(cdi_ABC_imputed))
#met for all models

# Linearity of Data
plot(cdi_PP_imputed, 1)
plot(cdi_ABC_imputed, 1)
#met for all models (I think)

# Predictors are Independent
durbinWatsonTest(cdi_PP_imputed)
durbinWatsonTest(cdi_ABC_imputed)
#met for all models except for cdi_PP_imputed (p = 0.008)

# Homoscedasticity
##plot
plot(cdi_PP_imputed, 3)
plot(cdi_ABC_imputed, 3)
## original Breusch-Pagan test
ncvTest(cdi_PP_imputed)
ncvTest(cdi_ABC_imputed)
# Half met the assumption. These models did not: drs_PP_imputed, cdi_ABC_imputed, anxiety_ABC_imputed, cts_ABC_imputed
## studentized Breusch-Pagan test
bptest(cdi_PP_imputed)
bptest(cdi_ABC_imputed)
#same outcome

# Normality of Residual Errors
ols_plot_resid_qq(cdi_PP_imputed)
ols_plot_resid_qq(cdi_ABC_imputed)
# use Kolmogorov-Smirnov test
ols_test_normality(cdi_PP_imputed)
ols_test_normality(cdi_ABC_imputed)
# the only model that meets this assumption is anxiety_PP_imputed
```


# Running Regressions (Nonimputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# Subset data based on condition

cope_ca_data_nonimputed_PP <- subset(cope_ca_data_nonimputed, condition == 1)
cope_ca_data_nonimputed_ABC <- subset(cope_ca_data_nonimputed, condition == 2)

# Run main regressions

# Project Personality, Nonnonimputed

cdi_PP_nonimputed <- lm(difference_score_cdi ~ difference_score_bhs + difference_score_shs + pi_pfs_mean, data = cope_ca_data_nonimputed_PP)
summary(cdi_PP_nonimputed)

# ABC Project, Nonnonimputed

cdi_ABC_nonimputed <- lm(difference_score_cdi ~ difference_score_bhs + difference_score_shs + pi_pfs_mean, data = cope_ca_data_nonimputed_ABC)
summary(cdi_ABC_nonimputed)
```
Note: We decided to use mean for the PFS instead of component scores.


# Commonality Analysis (Nonimputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# First, let's look at the r^2 for each model

summary(cdi_PP_nonimputed)$r.squared
summary(cdi_ABC_nonimputed)$r.squared

# Decompose r^2 # Let's just try this once for the model predicting follow-up depression symptoms for Project Personality 

regOut_cdi_PP <- calc.yhat(cdi_PP_nonimputed)
#regOut_cdi_PP$APSRelatedMetrics

# Bootstrap 1000 times to get CIs

boot.regOut_cdi_PP <-boot(cope_ca_data_nonimputed_PP, boot.yhat, 1000, lmOut = cdi_PP_nonimputed, regrout0 = regOut_cdi_PP)
boot.regOut_cdi_PP_result <- booteval.yhat(regOut_cdi_PP, boot.regOut_cdi_PP, bty="perc")
print(boot.regOut_cdi_PP_result$combCIaps)
print(boot.regOut_cdi_PP_result$combCIpm["b"])
print(boot.regOut_cdi_PP_result$combCIapsDiff)

# Hopelessness

rsq <- function(cope_ca_data_nonimputed_PP, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ difference_score_bhs,
    data = cope_ca_data_nonimputed_PP[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_nonimputed_PP, 1:nrow(cope_ca_data_nonimputed_PP)) 
bootstrapped_results <- boot(data = cope_ca_data_nonimputed_PP, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 

# Agency 

rsq <- function(cope_ca_data_nonimputed_PP, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ difference_score_shs,
    data = cope_ca_data_nonimputed_PP[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_nonimputed_PP, 1:nrow(cope_ca_data_nonimputed_PP)) 
bootstrapped_results <- boot(data = cope_ca_data_nonimputed_PP, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 

# Acceptability

rsq <- function(cope_ca_data_nonimputed_PP, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ pi_pfs_mean,
    data = cope_ca_data_nonimputed_PP[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_nonimputed_PP, 1:nrow(cope_ca_data_nonimputed_PP)) 
bootstrapped_results <- boot(data = cope_ca_data_nonimputed_PP, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 

# Project ABC, Depression

regOut_cdi_ABC <- calc.yhat(cdi_ABC_nonimputed)
#regOut_dep_ABC$APSRelatedMetrics

boot.regOut_cdi_ABC <- boot(cope_ca_data_nonimputed_ABC, boot.yhat, 1000, lmOut = cdi_ABC_nonimputed, regrout0 = regOut_cdi_ABC)
boot.regOut_cdi_ABC_result <- booteval.yhat(regOut_cdi_ABC, boot.regOut_cdi_ABC, bty = "perc")
print(boot.regOut_cdi_ABC_result$combCIaps)
print(boot.regOut_cdi_ABC_result$combCIpm["b"])
print(boot.regOut_cdi_ABC_result$combCIapsDiff)

# Hopelessness

rsq <- function(cope_ca_data_nonimputed_ABC, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ difference_score_bhs,
    data = cope_ca_data_nonimputed_ABC[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_nonimputed_ABC, 1:nrow(cope_ca_data_nonimputed_ABC)) 
bootstrapped_results <- boot(data = cope_ca_data_nonimputed_ABC, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 

# Agency 

rsq <- function(cope_ca_data_nonimputed_ABC, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ difference_score_shs,
    data = cope_ca_data_nonimputed_ABC[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_nonimputed_ABC, 1:nrow(cope_ca_data_nonimputed_ABC)) 
bootstrapped_results <- boot(data = cope_ca_data_nonimputed_ABC, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 

# Acceptability

rsq <- function(cope_ca_data_nonimputed_ABC, bootstrap_rows) { 
  model <- lm( 
    formula = difference_score_cdi ~ pi_pfs_mean,
    data = cope_ca_data_nonimputed_ABC[bootstrap_rows,] 
  ) 
  rsq <- summary(model)$r.squared 
  return(rsq) 
}
rsq(cope_ca_data_nonimputed_ABC, 1:nrow(cope_ca_data_nonimputed_ABC)) 
bootstrapped_results <- boot(data = cope_ca_data_nonimputed_ABC, statistic = rsq, R = 1000) 
boot.ci(bootstrapped_results, type = "perc") 
```


# Regression assumptions (Nonimputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# Multicollinearity
sqrt(vif(cdi_PP_nonimputed)) # should be less than 2
sqrt(vif(cdi_ABC_nonimputed))
#met for all models

# Linearity of Data
plot(cdi_PP_nonimputed, 1)
plot(cdi_ABC_nonimputed, 1)
#met for all models (I think)

# Predictors are Independent
durbinWatsonTest(cdi_PP_nonimputed)
durbinWatsonTest(cdi_ABC_nonimputed)
#met for all models except for cdi_PP_nonimputed (p = 0.008)

# Homoscedasticity
##plot
plot(cdi_PP_nonimputed, 3)
plot(cdi_ABC_nonimputed, 3)
## original Breusch-Pagan test
ncvTest(cdi_PP_nonimputed)
ncvTest(cdi_ABC_nonimputed)
# Half met the assumption. These models did not: drs_PP_nonimputed, cdi_ABC_nonimputed, anxiety_ABC_nonimputed, cts_ABC_nonimputed
## studentized Breusch-Pagan test
bptest(cdi_PP_nonimputed)
bptest(cdi_ABC_nonimputed)
#same outcome

# Normality of Residual Errors
ols_plot_resid_qq(cdi_PP_nonimputed)
ols_plot_resid_qq(cdi_ABC_nonimputed)
# use Kolmogorov-Smirnov test
ols_test_normality(cdi_PP_nonimputed)
ols_test_normality(cdi_ABC_nonimputed)
# the only model that meets this assumption is anxiety_PP_nonimputed
```

