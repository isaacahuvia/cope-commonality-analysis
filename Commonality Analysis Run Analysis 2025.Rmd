---
title: "Commonality Analysis Code_2"
author: "Laura Jans and Arielle Smith"
date: "2023-07-25"
output: html_document
---

# Loading Cleaned Data

```{r setup, echo=TRUE, message=FALSE, warning=FALSE}

#Load required packages

if(!require(tidyverse)){install.packages('tidyverse')}
library(tidyverse)

if(!require(psych)){install.packages('psych')}
library(psych)

if(!require(Hmisc)){install.packages('Hmisc')}
library(Hmisc)

if(!require(yhat)){install.packages('yhat')}
library(yhat)

if(!require(boot)){install.packages('boot')}
library(boot)

if(!require(VennDiagram)){install.packages('VennDiagram')}
library(VennDiagram)

if(!require(gsheet)){install.packages('gsheet')}
library('gsheet')

if(!require(ggrepel)){install.packages('ggrepel')}
library('ggrepel')

if(!require(stargazer)){install.packages('stargazer')}
library(stargazer)

if(!require(car)){install.packages('car')}
library(car)

if(!require(lmtest)){install.packages('lmtest')}
library(lmtest)

if(!require(olsrr)){install.packages('olsrr')}
library(olsrr)

#Read in data from data cleaning and pre-processing code (to avoid re-running data prep every time)

cope_ca_data_imputed <- read.csv("cope_ca_data_imputed.csv")
cope_ca_data_nonimputed <- read.csv("cope_ca_data_nonimputed.csv")

set.seed(6804275)
```


# Creating Difference Scores

## Dependent Variable
```{r}
#Creating difference scores for depression (pre-SSI to 3M) in both the imputed and non-imputed datasets
cope_ca_data_imputed <- cope_ca_data_imputed %>% 
  mutate(difference_score_cdi = f1_cdi_sum - b_cdi_sum)
cope_ca_data_nonimputed <- cope_ca_data_nonimputed %>% 
  mutate(difference_score_cdi = f1_cdi_sum - b_cdi_sum)
```

## Independent Variables

```{r}
#Creating difference scores for hopelessness (pre-SSI to post-SSI) in both the imputed and non-imputed datasets 
cope_ca_data_imputed <- cope_ca_data_imputed %>% 
  mutate(difference_score_bhs = pi_bhs_mean - b_bhs_mean)
cope_ca_data_nonimputed <- cope_ca_data_nonimputed %>% 
  mutate(difference_score_bhs = pi_bhs_mean - b_bhs_mean)

#Creating difference scores for agency (pre-SSI to post-SSI) in both the imputed and non-imputed datasets 
cope_ca_data_imputed <- cope_ca_data_imputed %>% 
  mutate(difference_score_shs = pi_shs_mean - b_shs_mean)
cope_ca_data_nonimputed <- cope_ca_data_nonimputed %>% 
  mutate(difference_score_shs = pi_shs_mean - b_shs_mean)
```


# Running Regressions (Imputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# Subset data based on condition

cope_ca_data_imputed_PP <- subset(cope_ca_data_imputed, condition == 1)
cope_ca_data_imputed_ABC <- subset(cope_ca_data_imputed, condition == 2)

# Run main regressions

# Project Personality, Imputed

cdi_PP_imputed <- lm(difference_score_cdi ~ difference_score_bhs + difference_score_shs + pi_pfs_mean, data = cope_ca_data_imputed_PP)
summary(cdi_PP_imputed)

# ABC Project, Imputed

cdi_ABC_imputed <- lm(difference_score_cdi ~ difference_score_bhs + difference_score_shs + pi_pfs_mean, data = cope_ca_data_imputed_ABC)
summary(cdi_ABC_imputed)
```
Note: We decided to use mean for the PFS instead of component scores.


# Commonality Analysis (Imputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# First, let's look at the r^2 for each model

summary(cdi_PP_imputed)$r.squared
summary(cdi_ABC_imputed)$r.squared

# Decompose r^2 # Let's just try this once for the model predicting follow-up depression symptoms for Project Personality 

regOut_cdi_PP <- calc.yhat(cdi_PP_imputed)
#regOut_cdi_PP$APSRelatedMetrics

# Bootstrap 1000 times to get CIs

boot.regOut_cdi_PP <-boot(cope_ca_data_imputed_PP, boot.yhat, 1000, lmOut = cdi_PP_imputed, regrout0 = regOut_cdi_PP)
boot.regOut_cdi_PP_result <- booteval.yhat(regOut_cdi_PP, boot.regOut_cdi_PP, bty="perc")
print(boot.regOut_cdi_PP_result$combCIaps)
print(boot.regOut_cdi_PP_result$combCIpm["b"])
print(boot.regOut_cdi_PP_result$combCIapsDiff)

# Project ABC, Depression

regOut_cdi_ABC <- calc.yhat(cdi_ABC_imputed)
#regOut_dep_ABC$APSRelatedMetrics

boot.regOut_cdi_ABC <- boot(cope_ca_data_imputed_ABC, boot.yhat, 1000, lmOut = cdi_ABC_imputed, regrout0 = regOut_cdi_ABC)
boot.regOut_cdi_ABC_result <- booteval.yhat(regOut_cdi_ABC, boot.regOut_cdi_ABC, bty = "perc")
print(boot.regOut_cdi_ABC_result$combCIaps)
print(boot.regOut_cdi_ABC_result$combCIpm["b"])
print(boot.regOut_cdi_ABC_result$combCIapsDiff)
```


# Regression assumptions (Imputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# Multicollinearity
sqrt(vif(cdi_PP_imputed)) # should be less than 2
sqrt(vif(cdi_ABC_imputed))
#met for all models

# Linearity of Data
plot(cdi_PP_imputed, 1)
plot(cdi_ABC_imputed, 1)
#met for all models (I think)

# Predictors are Independent
durbinWatsonTest(cdi_PP_imputed)
durbinWatsonTest(cdi_ABC_imputed)
#met for all models except for cdi_PP_imputed (p = 0.008)

# Homoscedasticity
##plot
plot(cdi_PP_imputed, 3)
plot(cdi_ABC_imputed, 3)
## original Breusch-Pagan test
ncvTest(cdi_PP_imputed)
ncvTest(cdi_ABC_imputed)
# Half met the assumption. These models did not: drs_PP_imputed, cdi_ABC_imputed, anxiety_ABC_imputed, cts_ABC_imputed
## studentized Breusch-Pagan test
bptest(cdi_PP_imputed)
bptest(cdi_ABC_imputed)
#same outcome

# Normality of Residual Errors
ols_plot_resid_qq(cdi_PP_imputed)
ols_plot_resid_qq(cdi_ABC_imputed)
# use Kolmogorov-Smirnov test
ols_test_normality(cdi_PP_imputed)
ols_test_normality(cdi_ABC_imputed)
# the only model that meets this assumption is anxiety_PP_imputed
```


# Running Regressions (Nonimputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# Subset data based on condition

cope_ca_data_nonimputed_PP <- subset(cope_ca_data_nonimputed, condition == 1)
cope_ca_data_nonimputed_ABC <- subset(cope_ca_data_nonimputed, condition == 2)

# Run main regressions

# Project Personality, Nonnonimputed

cdi_PP_nonimputed <- lm(difference_score_cdi ~ difference_score_bhs + difference_score_shs + pi_pfs_mean, data = cope_ca_data_nonimputed_PP)
summary(cdi_PP_nonimputed)

# ABC Project, Nonnonimputed

cdi_ABC_nonimputed <- lm(difference_score_cdi ~ difference_score_bhs + difference_score_shs + pi_pfs_mean, data = cope_ca_data_nonimputed_ABC)
summary(cdi_ABC_nonimputed)
```
Note: We decided to use mean for the PFS instead of component scores.


# Commonality Analysis (Nonimputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# First, let's look at the r^2 for each model

summary(cdi_PP_nonimputed)$r.squared
summary(cdi_ABC_nonimputed)$r.squared

# Decompose r^2 # Let's just try this once for the model predicting follow-up depression symptoms for Project Personality 

regOut_cdi_PP <- calc.yhat(cdi_PP_nonimputed)
#regOut_cdi_PP$APSRelatedMetrics

# Bootstrap 1000 times to get CIs

boot.regOut_cdi_PP <-boot(cope_ca_data_nonimputed_PP, boot.yhat, 1000, lmOut = cdi_PP_nonimputed, regrout0 = regOut_cdi_PP)
boot.regOut_cdi_PP_result <- booteval.yhat(regOut_cdi_PP, boot.regOut_cdi_PP, bty="perc")
print(boot.regOut_cdi_PP_result$combCIaps)
print(boot.regOut_cdi_PP_result$combCIpm["b"])
print(boot.regOut_cdi_PP_result$combCIapsDiff)

# Project ABC, Depression

regOut_cdi_ABC <- calc.yhat(cdi_ABC_nonimputed)
#regOut_dep_ABC$APSRelatedMetrics

boot.regOut_cdi_ABC <- boot(cope_ca_data_nonimputed_ABC, boot.yhat, 1000, lmOut = cdi_ABC_nonimputed, regrout0 = regOut_cdi_ABC)
boot.regOut_cdi_ABC_result <- booteval.yhat(regOut_cdi_ABC, boot.regOut_cdi_ABC, bty = "perc")
print(boot.regOut_cdi_ABC_result$combCIaps)
print(boot.regOut_cdi_ABC_result$combCIpm["b"])
print(boot.regOut_cdi_ABC_result$combCIapsDiff)
```


# Regression assumptions (Nonimputed)

```{r, results = "asis", include=T, echo = T, message=FALSE, warning=FALSE}

# Multicollinearity
sqrt(vif(cdi_PP_nonimputed)) # should be less than 2
sqrt(vif(cdi_ABC_nonimputed))
#met for all models

# Linearity of Data
plot(cdi_PP_nonimputed, 1)
plot(cdi_ABC_nonimputed, 1)
#met for all models (I think)

# Predictors are Independent
durbinWatsonTest(cdi_PP_nonimputed)
durbinWatsonTest(cdi_ABC_nonimputed)
#met for all models except for cdi_PP_nonimputed (p = 0.008)

# Homoscedasticity
##plot
plot(cdi_PP_nonimputed, 3)
plot(cdi_ABC_nonimputed, 3)
## original Breusch-Pagan test
ncvTest(cdi_PP_nonimputed)
ncvTest(cdi_ABC_nonimputed)
# Half met the assumption. These models did not: drs_PP_nonimputed, cdi_ABC_nonimputed, anxiety_ABC_nonimputed, cts_ABC_nonimputed
## studentized Breusch-Pagan test
bptest(cdi_PP_nonimputed)
bptest(cdi_ABC_nonimputed)
#same outcome

# Normality of Residual Errors
ols_plot_resid_qq(cdi_PP_nonimputed)
ols_plot_resid_qq(cdi_ABC_nonimputed)
# use Kolmogorov-Smirnov test
ols_test_normality(cdi_PP_nonimputed)
ols_test_normality(cdi_ABC_nonimputed)
# the only model that meets this assumption is anxiety_PP_nonimputed
```

